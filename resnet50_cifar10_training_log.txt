Using device cuda
Files already downloaded and verified
Training CIFAR-10 without pruning...
Epoch: 1, Training Loss: 2.3215, Training Accuracy: 28.99%, Validation Loss: 1.9514, Validation Accuracy: 36.87%
New best model found and saved with validation accuracy: 36.87%
Epoch: 2, Training Loss: 1.4918, Training Accuracy: 44.97%, Validation Loss: 1.7186, Validation Accuracy: 50.53%
New best model found and saved with validation accuracy: 50.53%
Epoch: 3, Training Loss: 1.3555, Training Accuracy: 51.16%, Validation Loss: 1.5723, Validation Accuracy: 51.54%
New best model found and saved with validation accuracy: 51.54%
Epoch: 4, Training Loss: 1.3097, Training Accuracy: 53.31%, Validation Loss: 1.2725, Validation Accuracy: 55.01%
New best model found and saved with validation accuracy: 55.01%
Epoch: 5, Training Loss: 1.1729, Training Accuracy: 58.24%, Validation Loss: 1.1424, Validation Accuracy: 60.17%
New best model found and saved with validation accuracy: 60.17%
Epoch: 6, Training Loss: 1.0234, Training Accuracy: 64.12%, Validation Loss: 1.0670, Validation Accuracy: 64.90%
New best model found and saved with validation accuracy: 64.90%
Epoch: 7, Training Loss: 0.9482, Training Accuracy: 66.88%, Validation Loss: 1.0073, Validation Accuracy: 65.08%
New best model found and saved with validation accuracy: 65.08%
Epoch: 8, Training Loss: 0.8468, Training Accuracy: 70.38%, Validation Loss: 0.8915, Validation Accuracy: 68.87%
New best model found and saved with validation accuracy: 68.87%
Epoch: 9, Training Loss: 0.5982, Training Accuracy: 79.11%, Validation Loss: 0.7112, Validation Accuracy: 75.45%
New best model found and saved with validation accuracy: 75.45%
Epoch: 10, Training Loss: 0.5164, Training Accuracy: 81.95%, Validation Loss: 0.7070, Validation Accuracy: 76.38%
New best model found and saved with validation accuracy: 76.38%
Plots saved as 'loss_plot.png' and 'accuracy_plot.png'
Pruning CIFAR-10 with 50.0% using method sensitivity...
Using device cuda
Files already downloaded and verified
Training CIFAR-10 without pruning...
Epoch: 1, Training Loss: 2.5071, Training Accuracy: 25.86%, Validation Loss: 2.1969, Validation Accuracy: 38.03%
New best model found and saved with validation accuracy: 38.03%
Epoch: 2, Training Loss: 1.6483, Training Accuracy: 39.18%, Validation Loss: 1.6013, Validation Accuracy: 42.45%
New best model found and saved with validation accuracy: 42.45%
Epoch: 3, Training Loss: 1.4422, Training Accuracy: 47.61%, Validation Loss: 1.3253, Validation Accuracy: 52.07%
New best model found and saved with validation accuracy: 52.07%
Epoch: 4, Training Loss: 1.3440, Training Accuracy: 51.57%, Validation Loss: 1.8363, Validation Accuracy: 43.34%
Epoch: 5, Training Loss: 1.2024, Training Accuracy: 57.40%, Validation Loss: 1.1716, Validation Accuracy: 59.31%
New best model found and saved with validation accuracy: 59.31%
Epoch: 6, Training Loss: 1.1179, Training Accuracy: 60.54%, Validation Loss: 1.1826, Validation Accuracy: 60.42%
New best model found and saved with validation accuracy: 60.42%
Epoch: 7, Training Loss: 1.0129, Training Accuracy: 64.60%, Validation Loss: 0.9993, Validation Accuracy: 64.82%
New best model found and saved with validation accuracy: 64.82%
Epoch: 8, Training Loss: 0.8662, Training Accuracy: 69.61%, Validation Loss: 0.8832, Validation Accuracy: 69.51%
New best model found and saved with validation accuracy: 69.51%
Epoch: 9, Training Loss: 0.6225, Training Accuracy: 78.13%, Validation Loss: 0.7730, Validation Accuracy: 74.36%
New best model found and saved with validation accuracy: 74.36%
Epoch: 10, Training Loss: 0.5326, Training Accuracy: 81.40%, Validation Loss: 0.7312, Validation Accuracy: 75.17%
New best model found and saved with validation accuracy: 75.17%
Epoch: 11, Training Loss: 0.4781, Training Accuracy: 83.34%, Validation Loss: 0.7256, Validation Accuracy: 75.97%
New best model found and saved with validation accuracy: 75.97%
Epoch: 12, Training Loss: 0.4171, Training Accuracy: 85.70%, Validation Loss: 0.7491, Validation Accuracy: 75.69%
Epoch: 13, Training Loss: 0.3463, Training Accuracy: 88.05%, Validation Loss: 0.7650, Validation Accuracy: 76.19%
New best model found and saved with validation accuracy: 76.19%
Epoch: 14, Training Loss: 0.2794, Training Accuracy: 90.34%, Validation Loss: 0.8228, Validation Accuracy: 76.24%
New best model found and saved with validation accuracy: 76.24%
Epoch: 15, Training Loss: 0.2168, Training Accuracy: 92.68%, Validation Loss: 0.9131, Validation Accuracy: 75.72%
Epoch: 16, Training Loss: 0.1709, Training Accuracy: 94.32%, Validation Loss: 0.9597, Validation Accuracy: 75.60%
Epoch: 17, Training Loss: 0.0920, Training Accuracy: 97.32%, Validation Loss: 0.9719, Validation Accuracy: 75.93%
Epoch: 18, Training Loss: 0.0718, Training Accuracy: 97.98%, Validation Loss: 1.0159, Validation Accuracy: 75.80%
Epoch: 19, Training Loss: 0.0608, Training Accuracy: 98.31%, Validation Loss: 1.0713, Validation Accuracy: 76.12%
Epoch: 20, Training Loss: 0.0517, Training Accuracy: 98.60%, Validation Loss: 1.1044, Validation Accuracy: 76.06%
Epoch: 21, Training Loss: 0.0458, Training Accuracy: 98.71%, Validation Loss: 1.1723, Validation Accuracy: 75.81%
Epoch: 22, Training Loss: 0.0381, Training Accuracy: 98.96%, Validation Loss: 1.2057, Validation Accuracy: 75.81%
Epoch: 23, Training Loss: 0.0343, Training Accuracy: 99.10%, Validation Loss: 1.2502, Validation Accuracy: 75.97%
Epoch: 24, Training Loss: 0.0309, Training Accuracy: 99.12%, Validation Loss: 1.2662, Validation Accuracy: 75.81%
Epoch: 25, Training Loss: 0.0262, Training Accuracy: 99.29%, Validation Loss: 1.2874, Validation Accuracy: 75.86%
Epoch: 26, Training Loss: 0.0254, Training Accuracy: 99.31%, Validation Loss: 1.2884, Validation Accuracy: 76.15%
Epoch: 27, Training Loss: 0.0243, Training Accuracy: 99.39%, Validation Loss: 1.3037, Validation Accuracy: 75.87%
Epoch: 28, Training Loss: 0.0242, Training Accuracy: 99.38%, Validation Loss: 1.2801, Validation Accuracy: 76.03%
Epoch: 29, Training Loss: 0.0239, Training Accuracy: 99.33%, Validation Loss: 1.2831, Validation Accuracy: 76.11%
Epoch: 30, Training Loss: 0.0240, Training Accuracy: 99.40%, Validation Loss: 1.2931, Validation Accuracy: 76.02%
Epoch: 31, Training Loss: 0.0233, Training Accuracy: 99.44%, Validation Loss: 1.3267, Validation Accuracy: 76.01%
Epoch: 32, Training Loss: 0.0216, Training Accuracy: 99.49%, Validation Loss: 1.3287, Validation Accuracy: 75.93%
Epoch: 33, Training Loss: 0.0220, Training Accuracy: 99.44%, Validation Loss: 1.3102, Validation Accuracy: 76.11%
Epoch: 34, Training Loss: 0.0212, Training Accuracy: 99.49%, Validation Loss: 1.3281, Validation Accuracy: 75.83%
Epoch: 35, Training Loss: 0.0204, Training Accuracy: 99.48%, Validation Loss: 1.3114, Validation Accuracy: 75.96%
Epoch: 36, Training Loss: 0.0214, Training Accuracy: 99.44%, Validation Loss: 1.3290, Validation Accuracy: 76.14%
Epoch: 37, Training Loss: 0.0218, Training Accuracy: 99.46%, Validation Loss: 1.3093, Validation Accuracy: 75.95%
Epoch: 38, Training Loss: 0.0213, Training Accuracy: 99.48%, Validation Loss: 1.3229, Validation Accuracy: 76.02%
Epoch: 39, Training Loss: 0.0214, Training Accuracy: 99.46%, Validation Loss: 1.3093, Validation Accuracy: 76.04%
Epoch: 40, Training Loss: 0.0212, Training Accuracy: 99.44%, Validation Loss: 1.3169, Validation Accuracy: 76.10%
Epoch: 41, Training Loss: 0.0214, Training Accuracy: 99.45%, Validation Loss: 1.3259, Validation Accuracy: 75.74%
Epoch: 42, Training Loss: 0.0214, Training Accuracy: 99.47%, Validation Loss: 1.3215, Validation Accuracy: 75.96%
Epoch: 43, Training Loss: 0.0201, Training Accuracy: 99.49%, Validation Loss: 1.3258, Validation Accuracy: 75.96%
Epoch: 44, Training Loss: 0.0206, Training Accuracy: 99.48%, Validation Loss: 1.3080, Validation Accuracy: 76.09%
Epoch: 45, Training Loss: 0.0220, Training Accuracy: 99.44%, Validation Loss: 1.3305, Validation Accuracy: 75.97%
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
Calculating baseline loss:   0%|                                                                | 0/40 [00:00<?, ?it/s]Calculating baseline loss:   0%|                                                                | 0/40 [00:00<?, ?it/s]
Calculating masks for each weight:   0%|                                                       | 0/161 [00:00<?, ?it/s]Calculating masks for each weight:   0%|                                                       | 0/161 [00:04<?, ?it/s]
Using device cuda
Files already downloaded and verified
Training CIFAR-10 without pruning...
Epoch: 1, Training Loss: 2.9853, Training Accuracy: 15.24%, Validation Loss: 2.5548, Validation Accuracy: 17.84%
New best model found and saved with validation accuracy: 17.84%
Epoch: 2, Training Loss: 2.0544, Training Accuracy: 26.77%, Validation Loss: 1.9346, Validation Accuracy: 32.05%
New best model found and saved with validation accuracy: 32.05%
Epoch: 3, Training Loss: 1.6712, Training Accuracy: 38.62%, Validation Loss: 1.5535, Validation Accuracy: 43.24%
New best model found and saved with validation accuracy: 43.24%
Epoch: 4, Training Loss: 1.4704, Training Accuracy: 45.92%, Validation Loss: 1.4109, Validation Accuracy: 47.86%
New best model found and saved with validation accuracy: 47.86%
Epoch: 5, Training Loss: 1.3330, Training Accuracy: 51.31%, Validation Loss: 1.3674, Validation Accuracy: 50.07%
New best model found and saved with validation accuracy: 50.07%
Epoch: 6, Training Loss: 1.2472, Training Accuracy: 55.00%, Validation Loss: 1.3186, Validation Accuracy: 52.11%
New best model found and saved with validation accuracy: 52.11%
Epoch: 7, Training Loss: 1.1231, Training Accuracy: 59.62%, Validation Loss: 1.1380, Validation Accuracy: 59.27%
New best model found and saved with validation accuracy: 59.27%
Epoch: 8, Training Loss: 1.0203, Training Accuracy: 63.51%, Validation Loss: 1.0898, Validation Accuracy: 61.16%
New best model found and saved with validation accuracy: 61.16%
Epoch: 9, Training Loss: 0.9282, Training Accuracy: 66.94%, Validation Loss: 0.9864, Validation Accuracy: 65.58%
New best model found and saved with validation accuracy: 65.58%
Epoch: 10, Training Loss: 0.8328, Training Accuracy: 70.54%, Validation Loss: 0.9666, Validation Accuracy: 66.88%
New best model found and saved with validation accuracy: 66.88%
Epoch: 11, Training Loss: 0.7467, Training Accuracy: 73.57%, Validation Loss: 0.9928, Validation Accuracy: 66.22%
Epoch: 12, Training Loss: 0.6710, Training Accuracy: 76.45%, Validation Loss: 0.9517, Validation Accuracy: 67.57%
New best model found and saved with validation accuracy: 67.57%
Epoch: 13, Training Loss: 0.6212, Training Accuracy: 78.30%, Validation Loss: 0.9301, Validation Accuracy: 69.56%
New best model found and saved with validation accuracy: 69.56%
Epoch: 14, Training Loss: 0.5473, Training Accuracy: 80.84%, Validation Loss: 0.9224, Validation Accuracy: 69.60%
New best model found and saved with validation accuracy: 69.60%
Epoch: 15, Training Loss: 0.4763, Training Accuracy: 83.50%, Validation Loss: 0.8897, Validation Accuracy: 71.13%
New best model found and saved with validation accuracy: 71.13%
Epoch: 16, Training Loss: 0.4266, Training Accuracy: 85.17%, Validation Loss: 0.8569, Validation Accuracy: 73.13%
New best model found and saved with validation accuracy: 73.13%
Epoch: 17, Training Loss: 0.3837, Training Accuracy: 86.50%, Validation Loss: 0.8982, Validation Accuracy: 71.82%
Epoch: 18, Training Loss: 0.3380, Training Accuracy: 88.17%, Validation Loss: 0.9596, Validation Accuracy: 72.52%
Epoch: 19, Training Loss: 0.2961, Training Accuracy: 89.78%, Validation Loss: 1.0311, Validation Accuracy: 72.15%
Epoch: 20, Training Loss: 0.2680, Training Accuracy: 90.63%, Validation Loss: 1.0423, Validation Accuracy: 71.60%
Epoch: 21, Training Loss: 0.3150, Training Accuracy: 89.02%, Validation Loss: 0.9493, Validation Accuracy: 73.71%
New best model found and saved with validation accuracy: 73.71%
Epoch: 22, Training Loss: 0.2029, Training Accuracy: 93.01%, Validation Loss: 1.1081, Validation Accuracy: 72.12%
Epoch: 23, Training Loss: 0.1748, Training Accuracy: 93.91%, Validation Loss: 1.0589, Validation Accuracy: 73.82%
New best model found and saved with validation accuracy: 73.82%
Epoch: 24, Training Loss: 0.1656, Training Accuracy: 94.26%, Validation Loss: 1.0520, Validation Accuracy: 73.95%
New best model found and saved with validation accuracy: 73.95%
Epoch: 25, Training Loss: 0.1549, Training Accuracy: 94.61%, Validation Loss: 1.0962, Validation Accuracy: 73.06%
Epoch: 26, Training Loss: 0.1436, Training Accuracy: 95.06%, Validation Loss: 1.1821, Validation Accuracy: 73.50%
Epoch: 27, Training Loss: 0.1486, Training Accuracy: 94.88%, Validation Loss: 1.0276, Validation Accuracy: 74.65%
New best model found and saved with validation accuracy: 74.65%
Epoch: 28, Training Loss: 0.1571, Training Accuracy: 94.44%, Validation Loss: 1.1549, Validation Accuracy: 73.43%
Epoch: 29, Training Loss: 0.1540, Training Accuracy: 94.72%, Validation Loss: 1.6503, Validation Accuracy: 74.56%
Epoch: 30, Training Loss: 0.1115, Training Accuracy: 96.13%, Validation Loss: 1.1392, Validation Accuracy: 74.02%
Epoch: 31, Training Loss: 0.0416, Training Accuracy: 98.67%, Validation Loss: 1.0721, Validation Accuracy: 77.06%
New best model found and saved with validation accuracy: 77.06%
Epoch: 32, Training Loss: 0.0160, Training Accuracy: 99.61%, Validation Loss: 1.1241, Validation Accuracy: 77.41%
New best model found and saved with validation accuracy: 77.41%
Epoch: 33, Training Loss: 0.0117, Training Accuracy: 99.68%, Validation Loss: 1.1929, Validation Accuracy: 77.26%
Epoch: 34, Training Loss: 0.0109, Training Accuracy: 99.64%, Validation Loss: 1.3970, Validation Accuracy: 77.31%
Epoch: 35, Training Loss: 0.0089, Training Accuracy: 99.73%, Validation Loss: 1.6950, Validation Accuracy: 77.25%
Epoch: 36, Training Loss: 0.0061, Training Accuracy: 99.84%, Validation Loss: 1.6523, Validation Accuracy: 77.02%
Epoch: 37, Training Loss: 0.0044, Training Accuracy: 99.90%, Validation Loss: 1.8110, Validation Accuracy: 77.16%
Epoch: 38, Training Loss: 0.0019, Training Accuracy: 99.96%, Validation Loss: 1.7722, Validation Accuracy: 77.16%
Epoch: 39, Training Loss: 0.0010, Training Accuracy: 99.97%, Validation Loss: 1.7846, Validation Accuracy: 77.52%
New best model found and saved with validation accuracy: 77.52%
Epoch: 40, Training Loss: 0.0009, Training Accuracy: 99.99%, Validation Loss: 1.8443, Validation Accuracy: 77.27%
Epoch: 41, Training Loss: 0.0012, Training Accuracy: 99.97%, Validation Loss: 1.8322, Validation Accuracy: 77.55%
New best model found and saved with validation accuracy: 77.55%
Epoch: 42, Training Loss: 0.0008, Training Accuracy: 99.97%, Validation Loss: 1.8999, Validation Accuracy: 77.24%
Epoch: 43, Training Loss: 0.0012, Training Accuracy: 99.97%, Validation Loss: 1.8771, Validation Accuracy: 77.37%
Epoch: 44, Training Loss: 0.0017, Training Accuracy: 99.95%, Validation Loss: 1.9551, Validation Accuracy: 76.91%
Epoch: 45, Training Loss: 0.0018, Training Accuracy: 99.96%, Validation Loss: 1.8727, Validation Accuracy: 77.22%
Epoch: 46, Training Loss: 0.0007, Training Accuracy: 99.98%, Validation Loss: 1.9091, Validation Accuracy: 77.65%
New best model found and saved with validation accuracy: 77.65%
Epoch: 47, Training Loss: 0.0008, Training Accuracy: 99.98%, Validation Loss: 1.9483, Validation Accuracy: 77.10%
Epoch: 48, Training Loss: 0.0010, Training Accuracy: 99.99%, Validation Loss: 1.9962, Validation Accuracy: 77.20%
Epoch: 49, Training Loss: 0.0034, Training Accuracy: 99.90%, Validation Loss: 1.9621, Validation Accuracy: 76.61%
Epoch: 50, Training Loss: 0.0057, Training Accuracy: 99.81%, Validation Loss: 1.7432, Validation Accuracy: 77.34%
Epoch: 51, Training Loss: 0.0022, Training Accuracy: 99.92%, Validation Loss: 1.7950, Validation Accuracy: 77.63%
Epoch: 52, Training Loss: 0.0019, Training Accuracy: 99.92%, Validation Loss: 1.8467, Validation Accuracy: 77.13%
Epoch: 53, Training Loss: 0.0026, Training Accuracy: 99.92%, Validation Loss: 1.8613, Validation Accuracy: 77.13%
Epoch: 54, Training Loss: 0.0041, Training Accuracy: 99.88%, Validation Loss: 1.8134, Validation Accuracy: 76.93%
Epoch: 55, Training Loss: 0.0029, Training Accuracy: 99.91%, Validation Loss: 1.7795, Validation Accuracy: 77.36%
Epoch: 56, Training Loss: 0.0013, Training Accuracy: 99.97%, Validation Loss: 1.8502, Validation Accuracy: 77.38%
Epoch: 57, Training Loss: 0.0011, Training Accuracy: 99.97%, Validation Loss: 1.9539, Validation Accuracy: 77.23%
Epoch: 58, Training Loss: 0.0053, Training Accuracy: 99.84%, Validation Loss: 1.8529, Validation Accuracy: 77.18%
Epoch: 59, Training Loss: 0.0028, Training Accuracy: 99.90%, Validation Loss: 1.8379, Validation Accuracy: 77.00%
Epoch: 60, Training Loss: 0.0022, Training Accuracy: 99.92%, Validation Loss: 1.8622, Validation Accuracy: 76.89%
Epoch: 61, Training Loss: 0.0010, Training Accuracy: 99.97%, Validation Loss: 1.8506, Validation Accuracy: 77.20%
Epoch: 62, Training Loss: 0.0005, Training Accuracy: 99.99%, Validation Loss: 1.8666, Validation Accuracy: 77.09%
Epoch: 63, Training Loss: 0.0003, Training Accuracy: 100.00%, Validation Loss: 1.8996, Validation Accuracy: 77.04%
Epoch: 64, Training Loss: 0.0004, Training Accuracy: 99.99%, Validation Loss: 1.8592, Validation Accuracy: 77.18%
Epoch: 65, Training Loss: 0.0002, Training Accuracy: 100.00%, Validation Loss: 1.8680, Validation Accuracy: 77.06%
Epoch: 66, Training Loss: 0.0002, Training Accuracy: 100.00%, Validation Loss: 1.8893, Validation Accuracy: 77.22%
Epoch: 67, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.8987, Validation Accuracy: 77.35%
Epoch: 68, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.8918, Validation Accuracy: 77.28%
Epoch: 69, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.8936, Validation Accuracy: 77.46%
Epoch: 70, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9230, Validation Accuracy: 77.15%
Epoch: 71, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9108, Validation Accuracy: 77.43%
Epoch: 72, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9357, Validation Accuracy: 77.35%
Epoch: 73, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9426, Validation Accuracy: 77.34%
Epoch: 74, Training Loss: 0.0002, Training Accuracy: 100.00%, Validation Loss: 1.9378, Validation Accuracy: 77.20%
Epoch: 75, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9723, Validation Accuracy: 77.33%
Epoch: 76, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9815, Validation Accuracy: 77.40%
Epoch: 77, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9812, Validation Accuracy: 77.37%
Epoch: 78, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9855, Validation Accuracy: 77.38%
Epoch: 79, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 1.9891, Validation Accuracy: 77.57%
Epoch: 80, Training Loss: 0.0001, Training Accuracy: 100.00%, Validation Loss: 2.0135, Validation Accuracy: 77.43%
Epoch: 81, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0425, Validation Accuracy: 77.51%
Epoch: 82, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0207, Validation Accuracy: 77.72%
New best model found and saved with validation accuracy: 77.72%
Epoch: 83, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0381, Validation Accuracy: 77.64%
Epoch: 84, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0378, Validation Accuracy: 77.40%
Epoch: 85, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0364, Validation Accuracy: 77.54%
Epoch: 86, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0886, Validation Accuracy: 77.50%
Epoch: 87, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.1015, Validation Accuracy: 77.59%
Epoch: 88, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.0993, Validation Accuracy: 77.62%
Epoch: 89, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.1400, Validation Accuracy: 77.44%
Epoch: 90, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 2.1075, Validation Accuracy: 77.70%
Plots saved as 'loss_plot.png' and 'accuracy_plot.png'
Calculating baseline loss:   0%|                                                                | 0/40 [00:00<?, ?it/s]Calculating baseline loss:   0%|                                                                | 0/40 [00:00<?, ?it/s]
Calculating masks for each weight:   0%|                                                       | 0/161 [00:00<?, ?it/s]Calculating masks for each weight:   1%|2                                          | 1/161 [10:50<28:54:53, 650.59s/it]Calculating masks for each weight:   1%|5                                          | 2/161 [10:55<11:56:47, 270.49s/it]Calculating masks for each weight:   2%|8                                           | 3/161 [10:59<6:32:23, 149.01s/it]Calculating masks for each weight:   2%|#                                           | 4/161 [15:42<8:48:28, 201.96s/it]Calculating masks for each weight:   3%|#3                                          | 5/161 [15:47<5:39:56, 130.75s/it]Calculating masks for each weight:   4%|#6                                           | 6/161 [15:51<3:46:50, 87.81s/it]Calculating masks for each weight:   4%|#6                                         | 6/161 [40:16<17:20:30, 402.78s/it]
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]
Calculating sensitivities:   0%|                                                               | 0/161 [00:00<?, ?it/s]
Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]

Calculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s][ACalculating loss:   0%|                                                                         | 0/40 [00:00<?, ?it/s]
Calculating sensitivities:   0%|                                                               | 0/161 [00:20<?, ?it/s]
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
Calculating sensitivities:   0%|                                                               | 0/161 [00:00<?, ?it/s]Calculating sensitivities:   0%|                                                               | 0/161 [00:15<?, ?it/s]
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
Calculating sensitivities:   0%|                                                               | 0/161 [00:00<?, ?it/s]Calculating sensitivities:   1%|3                                                      | 1/161 [00:04<11:09,  4.18s/it]Calculating sensitivities:   1%|6                                                      | 2/161 [00:08<11:17,  4.26s/it]Calculating sensitivities:   2%|#                                                      | 3/161 [00:13<11:32,  4.38s/it]Calculating sensitivities:   2%|#3                                                     | 4/161 [00:17<11:36,  4.44s/it]Calculating sensitivities:   3%|#7                                                     | 5/161 [00:22<11:38,  4.48s/it]Calculating sensitivities:   4%|##                                                     | 6/161 [00:26<11:37,  4.50s/it]Calculating sensitivities:   4%|##3                                                    | 7/161 [00:31<11:34,  4.51s/it]Calculating sensitivities:   5%|##7                                                    | 8/161 [00:35<11:30,  4.51s/it]Calculating sensitivities:   6%|###                                                    | 9/161 [00:40<11:27,  4.52s/it]Calculating sensitivities:   6%|###3                                                  | 10/161 [00:58<21:53,  8.70s/it]Calculating sensitivities:   7%|###6                                                  | 11/161 [01:16<28:55, 11.57s/it]Calculating sensitivities:   7%|####                                                  | 12/161 [01:34<33:40, 13.56s/it]Calculating sensitivities:   8%|####3                                                 | 13/161 [01:52<36:48, 14.92s/it]Calculating sensitivities:   9%|####6                                                 | 14/161 [02:10<38:56, 15.90s/it]Calculating sensitivities:   9%|#####                                                 | 15/161 [02:28<40:21, 16.59s/it]Calculating sensitivities:  10%|#####3                                                | 16/161 [02:33<31:19, 12.96s/it]Calculating sensitivities:  11%|#####7                                                | 17/161 [02:37<25:01, 10.43s/it]Calculating sensitivities:  11%|######                                                | 18/161 [02:42<20:38,  8.66s/it]Calculating sensitivities:  12%|######3                                               | 19/161 [02:47<17:32,  7.41s/it]Calculating sensitivities:  12%|######7                                               | 20/161 [02:51<15:22,  6.55s/it]Calculating sensitivities:  13%|#######                                               | 21/161 [02:56<13:53,  5.95s/it]Calculating sensitivities:  14%|#######3                                              | 22/161 [03:14<22:14,  9.60s/it]Calculating sensitivities:  14%|#######7                                              | 23/161 [03:32<27:56, 12.15s/it]Calculating sensitivities:  15%|########                                              | 24/161 [03:50<31:50, 13.94s/it]Calculating sensitivities:  16%|########3                                             | 25/161 [03:54<25:11, 11.12s/it]Calculating sensitivities:  16%|########7                                             | 26/161 [03:59<20:36,  9.16s/it]Calculating sensitivities:  17%|#########                                             | 27/161 [04:04<17:22,  7.78s/it]Calculating sensitivities:  17%|#########3                                            | 28/161 [04:08<15:04,  6.80s/it]Calculating sensitivities:  18%|#########7                                            | 29/161 [04:13<13:28,  6.12s/it]Calculating sensitivities:  19%|##########                                            | 30/161 [04:17<12:19,  5.65s/it]Calculating sensitivities:  19%|##########3                                           | 31/161 [04:35<20:16,  9.36s/it]Calculating sensitivities:  20%|##########7                                           | 32/161 [04:53<25:41, 11.95s/it]Calculating sensitivities:  20%|###########                                           | 33/161 [05:11<29:25, 13.79s/it]Calculating sensitivities:  21%|###########4                                          | 34/161 [05:20<26:09, 12.36s/it]Calculating sensitivities:  22%|###########7                                          | 35/161 [05:29<23:51, 11.36s/it]Calculating sensitivities:  22%|############                                          | 36/161 [05:38<22:10, 10.65s/it]Calculating sensitivities:  23%|############4                                         | 37/161 [05:47<20:58, 10.15s/it]Calculating sensitivities:  24%|############7                                         | 38/161 [05:56<20:06,  9.81s/it]Calculating sensitivities:  24%|#############                                         | 39/161 [06:05<19:27,  9.57s/it]Calculating sensitivities:  25%|#############4                                        | 40/161 [06:41<35:16, 17.49s/it]Calculating sensitivities:  25%|#############7                                        | 41/161 [07:17<46:05, 23.05s/it]Calculating sensitivities:  26%|##############                                        | 42/161 [07:53<53:24, 26.93s/it]Calculating sensitivities:  27%|##############4                                       | 43/161 [08:29<58:16, 29.63s/it]Calculating sensitivities:  27%|##############2                                     | 44/161 [09:05<1:01:34, 31.58s/it]Calculating sensitivities:  28%|##############5                                     | 45/161 [09:41<1:03:38, 32.92s/it]Calculating sensitivities:  29%|###############4                                      | 46/161 [09:50<49:20, 25.74s/it]Calculating sensitivities:  29%|###############7                                      | 47/161 [09:59<39:21, 20.71s/it]Calculating sensitivities:  30%|################                                      | 48/161 [10:08<32:23, 17.20s/it]Calculating sensitivities:  30%|################4                                     | 49/161 [10:17<27:29, 14.73s/it]Calculating sensitivities:  31%|################7                                     | 50/161 [10:26<24:03, 13.01s/it]Calculating sensitivities:  32%|#################1                                    | 51/161 [10:35<21:40, 11.82s/it]Calculating sensitivities:  32%|#################4                                    | 52/161 [11:12<34:56, 19.23s/it]Calculating sensitivities:  33%|#################7                                    | 53/161 [11:48<43:30, 24.17s/it]Calculating sensitivities:  34%|##################1                                   | 54/161 [12:23<49:20, 27.67s/it]Calculating sensitivities:  34%|##################4                                   | 55/161 [12:33<39:02, 22.10s/it]Calculating sensitivities:  35%|##################7                                   | 56/161 [12:42<31:50, 18.20s/it]Calculating sensitivities:  35%|###################1                                  | 57/161 [12:50<26:39, 15.38s/it]Calculating sensitivities:  36%|###################4                                  | 58/161 [13:00<23:08, 13.48s/it]Calculating sensitivities:  37%|###################7                                  | 59/161 [13:08<20:33, 12.09s/it]Calculating sensitivities:  37%|####################1                                 | 60/161 [13:18<18:52, 11.22s/it]Calculating sensitivities:  38%|####################4                                 | 61/161 [13:53<30:52, 18.53s/it]Calculating sensitivities:  39%|####################7                                 | 62/161 [14:30<39:40, 24.04s/it]Calculating sensitivities:  39%|#####################1                                | 63/161 [15:07<45:29, 27.85s/it]Calculating sensitivities:  40%|#####################4                                | 64/161 [15:16<35:50, 22.17s/it]Calculating sensitivities:  40%|#####################8                                | 65/161 [15:25<29:10, 18.23s/it]Calculating sensitivities:  41%|######################1                               | 66/161 [15:34<24:30, 15.48s/it]Calculating sensitivities:  42%|######################4                               | 67/161 [15:43<21:14, 13.56s/it]Calculating sensitivities:  42%|######################8                               | 68/161 [15:52<18:53, 12.19s/it]Calculating sensitivities:  43%|#######################1                              | 69/161 [16:01<17:15, 11.26s/it]Calculating sensitivities:  43%|#######################4                              | 70/161 [16:37<28:26, 18.75s/it]Calculating sensitivities:  44%|#######################8                              | 71/161 [17:14<36:02, 24.02s/it]Calculating sensitivities:  45%|########################1                             | 72/161 [17:50<41:05, 27.71s/it]Calculating sensitivities:  45%|########################4                             | 73/161 [18:08<36:26, 24.85s/it]Calculating sensitivities:  46%|########################8                             | 74/161 [18:26<33:06, 22.84s/it]Calculating sensitivities:  47%|#########################1                            | 75/161 [18:44<30:42, 21.43s/it]Calculating sensitivities:  47%|#########################4                            | 76/161 [19:02<28:58, 20.45s/it]Calculating sensitivities:  48%|#########################8                            | 77/161 [19:21<27:42, 19.79s/it]Calculating sensitivities:  48%|##########################1                           | 78/161 [19:39<26:42, 19.30s/it]Calculating sensitivities:  49%|##########################4                           | 79/161 [20:51<48:09, 35.24s/it]Calculating sensitivities:  50%|#########################8                          | 80/161 [22:04<1:02:41, 46.44s/it]Calculating sensitivities:  50%|##########################1                         | 81/161 [23:17<1:12:25, 54.31s/it]Calculating sensitivities:  51%|##########################4                         | 82/161 [24:29<1:18:43, 59.79s/it]Calculating sensitivities:  52%|##########################8                         | 83/161 [25:41<1:22:35, 63.53s/it]Calculating sensitivities:  52%|###########################1                        | 84/161 [26:54<1:24:51, 66.12s/it]Calculating sensitivities:  53%|###########################4                        | 85/161 [27:12<1:05:28, 51.69s/it]Calculating sensitivities:  53%|############################8                         | 86/161 [27:30<52:00, 41.61s/it]Calculating sensitivities:  54%|#############################1                        | 87/161 [27:48<42:36, 34.55s/it]Calculating sensitivities:  55%|#############################5                        | 88/161 [28:06<36:00, 29.60s/it]Calculating sensitivities:  55%|#############################8                        | 89/161 [28:24<31:22, 26.15s/it]Calculating sensitivities:  56%|##############################1                       | 90/161 [28:42<28:05, 23.75s/it]Calculating sensitivities:  57%|##############################5                       | 91/161 [29:54<44:45, 38.36s/it]Calculating sensitivities:  57%|##############################8                       | 92/161 [31:07<55:52, 48.59s/it]Calculating sensitivities:  58%|##############################                      | 93/161 [32:19<1:03:08, 55.71s/it]Calculating sensitivities:  58%|###############################5                      | 94/161 [32:38<49:40, 44.49s/it]Calculating sensitivities:  59%|###############################8                      | 95/161 [32:56<40:16, 36.61s/it]Calculating sensitivities:  60%|################################1                     | 96/161 [33:14<33:38, 31.05s/it]Calculating sensitivities:  60%|################################5                     | 97/161 [33:32<28:58, 27.16s/it]Calculating sensitivities:  61%|################################8                     | 98/161 [33:50<25:41, 24.47s/it]Calculating sensitivities:  61%|#################################2                    | 99/161 [34:09<23:24, 22.65s/it]Calculating sensitivities:  62%|################################9                    | 100/161 [35:21<38:15, 37.63s/it]Calculating sensitivities:  63%|#################################2                   | 101/161 [36:33<48:01, 48.03s/it]Calculating sensitivities:  63%|#################################5                   | 102/161 [37:46<54:34, 55.50s/it]Calculating sensitivities:  64%|#################################9                   | 103/161 [38:05<42:51, 44.34s/it]Calculating sensitivities:  65%|##################################2                  | 104/161 [38:23<34:43, 36.55s/it]Calculating sensitivities:  65%|##################################5                  | 105/161 [38:41<28:59, 31.06s/it]Calculating sensitivities:  66%|##################################8                  | 106/161 [39:00<24:58, 27.24s/it]Calculating sensitivities:  66%|###################################2                 | 107/161 [39:18<22:06, 24.57s/it]Calculating sensitivities:  67%|###################################5                 | 108/161 [39:36<20:02, 22.70s/it]Calculating sensitivities:  68%|###################################8                 | 109/161 [40:49<32:48, 37.85s/it]Calculating sensitivities:  68%|####################################2                | 110/161 [42:03<41:13, 48.50s/it]Calculating sensitivities:  69%|####################################5                | 111/161 [43:16<46:37, 55.94s/it]Calculating sensitivities:  70%|####################################8                | 112/161 [43:34<36:28, 44.66s/it]Calculating sensitivities:  70%|#####################################1               | 113/161 [43:53<29:24, 36.75s/it]Calculating sensitivities:  71%|#####################################5               | 114/161 [44:11<24:27, 31.22s/it]Calculating sensitivities:  71%|#####################################8               | 115/161 [44:29<20:57, 27.35s/it]Calculating sensitivities:  72%|######################################1              | 116/161 [44:48<18:27, 24.61s/it]Calculating sensitivities:  73%|######################################5              | 117/161 [45:06<16:39, 22.73s/it]Calculating sensitivities:  73%|######################################8              | 118/161 [46:19<27:06, 37.83s/it]Calculating sensitivities:  74%|#######################################1             | 119/161 [47:32<33:51, 48.38s/it]Calculating sensitivities:  75%|#######################################5             | 120/161 [48:44<37:59, 55.59s/it]Calculating sensitivities:  75%|#######################################8             | 121/161 [49:02<29:31, 44.29s/it]Calculating sensitivities:  76%|########################################1            | 122/161 [49:21<23:43, 36.50s/it]Calculating sensitivities:  76%|########################################4            | 123/161 [49:39<19:38, 31.02s/it]Calculating sensitivities:  77%|########################################8            | 124/161 [49:57<16:46, 27.20s/it]Calculating sensitivities:  78%|#########################################1           | 125/161 [50:15<14:43, 24.54s/it]Calculating sensitivities:  78%|#########################################4           | 126/161 [50:34<13:13, 22.66s/it]Calculating sensitivities:  79%|#########################################8           | 127/161 [51:47<21:22, 37.73s/it]Calculating sensitivities:  80%|##########################################1          | 128/161 [52:59<26:27, 48.12s/it]Calculating sensitivities:  80%|##########################################4          | 129/161 [54:12<29:34, 55.46s/it]Calculating sensitivities:  81%|##########################################7          | 130/161 [54:48<25:43, 49.80s/it]Calculating sensitivities:  81%|###########################################1         | 131/161 [55:25<22:57, 45.92s/it]Calculating sensitivities:  82%|###########################################4         | 132/161 [56:02<20:50, 43.12s/it]Calculating sensitivities:  83%|###########################################7         | 133/161 [56:38<19:09, 41.05s/it]Calculating sensitivities:  83%|############################################1        | 134/161 [57:14<17:48, 39.58s/it]Calculating sensitivities:  84%|############################################4        | 135/161 [57:51<16:46, 38.71s/it]Calculating sensitivities:  84%|###########################################        | 136/161 [1:00:17<29:31, 70.85s/it]Calculating sensitivities:  85%|###########################################3       | 137/161 [1:02:43<37:22, 93.44s/it]Calculating sensitivities:  86%|##########################################8       | 138/161 [1:05:09<41:52, 109.26s/it]Calculating sensitivities:  86%|###########################################1      | 139/161 [1:07:34<44:02, 120.12s/it]Calculating sensitivities:  87%|###########################################4      | 140/161 [1:10:00<44:45, 127.87s/it]Calculating sensitivities:  88%|###########################################7      | 141/161 [1:12:28<44:36, 133.81s/it]Calculating sensitivities:  88%|############################################      | 142/161 [1:13:04<33:07, 104.61s/it]Calculating sensitivities:  89%|#############################################2     | 143/161 [1:13:41<25:14, 84.15s/it]Calculating sensitivities:  89%|#############################################6     | 144/161 [1:14:17<19:46, 69.80s/it]Calculating sensitivities:  90%|#############################################9     | 145/161 [1:14:53<15:55, 59.74s/it]Calculating sensitivities:  91%|##############################################2    | 146/161 [1:15:30<13:11, 52.74s/it]Calculating sensitivities:  91%|##############################################5    | 147/161 [1:16:06<11:09, 47.84s/it]Calculating sensitivities:  92%|##############################################8    | 148/161 [1:18:32<16:45, 77.34s/it]Calculating sensitivities:  93%|##############################################2   | 149/161 [1:21:10<20:17, 101.46s/it]Calculating sensitivities:  93%|##############################################5   | 150/161 [1:23:41<21:18, 116.19s/it]Calculating sensitivities:  94%|###############################################8   | 151/161 [1:24:17<15:21, 92.16s/it]Calculating sensitivities:  94%|################################################1  | 152/161 [1:24:53<11:18, 75.36s/it]Calculating sensitivities:  95%|################################################4  | 153/161 [1:25:29<08:28, 63.59s/it]Calculating sensitivities:  96%|################################################7  | 154/161 [1:26:05<06:27, 55.31s/it]Calculating sensitivities:  96%|#################################################  | 155/161 [1:26:41<04:57, 49.58s/it]Calculating sensitivities:  97%|#################################################4 | 156/161 [1:27:17<03:47, 45.56s/it]Calculating sensitivities:  98%|#################################################7 | 157/161 [1:29:42<05:00, 75.15s/it]Calculating sensitivities:  98%|################################################## | 158/161 [1:32:06<04:47, 95.86s/it]Calculating sensitivities:  99%|#################################################3| 159/161 [1:34:31<03:41, 110.66s/it]Calculating sensitivities:  99%|#################################################6| 160/161 [1:58:48<08:34, 514.53s/it]Calculating sensitivities: 100%|##################################################| 161/161 [1:58:49<00:00, 360.39s/it]Calculating sensitivities: 100%|###################################################| 161/161 [1:58:49<00:00, 44.28s/it]
Pruning weights:   0%|                                                                       | 0/50085 [00:00<?, ?it/s]Pruning weights:   0%|                                                                       | 0/50085 [00:00<?, ?it/s]
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
: ResNet50(
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=10, bias=True)
  )
)
model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)
model.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
model.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.relu: ReLU(inplace=True)
model.maxpool: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
model.layer1: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer1.0: Bottleneck(
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer1.0.conv1: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.0.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.relu: ReLU(inplace=True)
model.layer1.0.downsample: Sequential(
  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer1.0.downsample.0: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.downsample.1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.1.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.1.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.relu: ReLU(inplace=True)
model.layer1.2: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.2.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.2.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.relu: ReLU(inplace=True)
model.layer2: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer2.0: Bottleneck(
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer2.0.conv1: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer2.0.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.relu: ReLU(inplace=True)
model.layer2.0.downsample: Sequential(
  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer2.0.downsample.0: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer2.0.downsample.1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.1.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.1.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.relu: ReLU(inplace=True)
model.layer2.2: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.2.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.2.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.relu: ReLU(inplace=True)
model.layer2.3: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.3.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.3.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.relu: ReLU(inplace=True)
model.layer3: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (4): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (5): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer3.0: Bottleneck(
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer3.0.conv1: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer3.0.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.relu: ReLU(inplace=True)
model.layer3.0.downsample: Sequential(
  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer3.0.downsample.0: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer3.0.downsample.1: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.1.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.1.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.relu: ReLU(inplace=True)
model.layer3.2: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.2.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.2.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.relu: ReLU(inplace=True)
model.layer3.3: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.3.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.3.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.relu: ReLU(inplace=True)
model.layer3.4: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.4.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.4.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.relu: ReLU(inplace=True)
model.layer3.5: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.5.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.5.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.relu: ReLU(inplace=True)
model.layer4: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer4.0: Bottleneck(
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer4.0.conv1: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer4.0.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.relu: ReLU(inplace=True)
model.layer4.0.downsample: Sequential(
  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer4.0.downsample.0: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer4.0.downsample.1: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.1.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.1.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.relu: ReLU(inplace=True)
model.layer4.2: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.2.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.2.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.relu: ReLU(inplace=True)
model.avgpool: AdaptiveAvgPool2d(output_size=(1, 1))
model.fc: Linear(in_features=2048, out_features=10, bias=True)
Calculating sensitivities:   0%|                                                            | 0/161 [00:00<?, ?it/s]Calculating sensitivities:   0%|                                                            | 0/161 [00:02<?, ?it/s]
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
: ResNet50(
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=10, bias=True)
  )
)
model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)
model.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
model.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.relu: ReLU(inplace=True)
model.maxpool: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
model.layer1: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer1.0: Bottleneck(
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer1.0.conv1: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.0.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.relu: ReLU(inplace=True)
model.layer1.0.downsample: Sequential(
  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer1.0.downsample.0: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.downsample.1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.1.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.1.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.relu: ReLU(inplace=True)
model.layer1.2: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.2.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.2.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.relu: ReLU(inplace=True)
model.layer2: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer2.0: Bottleneck(
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer2.0.conv1: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer2.0.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.relu: ReLU(inplace=True)
model.layer2.0.downsample: Sequential(
  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer2.0.downsample.0: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer2.0.downsample.1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.1.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.1.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.relu: ReLU(inplace=True)
model.layer2.2: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.2.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.2.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.relu: ReLU(inplace=True)
model.layer2.3: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.3.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.3.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.relu: ReLU(inplace=True)
model.layer3: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (4): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (5): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer3.0: Bottleneck(
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer3.0.conv1: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer3.0.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.relu: ReLU(inplace=True)
model.layer3.0.downsample: Sequential(
  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer3.0.downsample.0: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer3.0.downsample.1: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.1.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.1.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.relu: ReLU(inplace=True)
model.layer3.2: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.2.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.2.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.relu: ReLU(inplace=True)
model.layer3.3: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.3.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.3.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.relu: ReLU(inplace=True)
model.layer3.4: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.4.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.4.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.relu: ReLU(inplace=True)
model.layer3.5: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.5.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.5.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.relu: ReLU(inplace=True)
model.layer4: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer4.0: Bottleneck(
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer4.0.conv1: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer4.0.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.relu: ReLU(inplace=True)
model.layer4.0.downsample: Sequential(
  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer4.0.downsample.0: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer4.0.downsample.1: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.1.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.1.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.relu: ReLU(inplace=True)
model.layer4.2: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.2.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.2.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.relu: ReLU(inplace=True)
model.avgpool: AdaptiveAvgPool2d(output_size=(1, 1))
model.fc: Linear(in_features=2048, out_features=10, bias=True)
Calculating sensitivities:   0%|                                                                        | 0/161 [00:00<?, ?it/s]Calculating sensitivities:   1%|3                                                               | 1/161 [00:04<10:51,  4.07s/it]Calculating sensitivities:   1%|7                                                               | 2/161 [00:08<11:04,  4.18s/it]Calculating sensitivities:   2%|#1                                                              | 3/161 [00:12<11:13,  4.26s/it]Calculating sensitivities:   2%|#5                                                              | 4/161 [00:17<11:18,  4.32s/it]Calculating sensitivities:   3%|#9                                                              | 5/161 [00:21<11:19,  4.35s/it]Calculating sensitivities:   4%|##3                                                             | 6/161 [00:25<11:18,  4.37s/it]Calculating sensitivities:   4%|##7                                                             | 7/161 [00:30<11:14,  4.38s/it]Calculating sensitivities:   5%|###1                                                            | 8/161 [00:34<11:12,  4.39s/it]Calculating sensitivities:   6%|###5                                                            | 9/161 [00:39<11:08,  4.40s/it]Calculating sensitivities:   6%|###9                                                           | 10/161 [00:56<21:20,  8.48s/it]Calculating sensitivities:   7%|####3                                                          | 11/161 [01:14<28:10, 11.27s/it]Calculating sensitivities:   7%|####6                                                          | 12/161 [01:32<32:48, 13.21s/it]Calculating sensitivities:   8%|#####                                                          | 13/161 [01:49<35:52, 14.54s/it]Calculating sensitivities:   9%|#####4                                                         | 14/161 [02:07<37:55, 15.48s/it]Calculating sensitivities:   9%|#####8                                                         | 15/161 [02:24<39:08, 16.08s/it]Calculating sensitivities:  10%|######2                                                        | 16/161 [02:29<30:20, 12.55s/it]Calculating sensitivities:  11%|######6                                                        | 17/161 [02:33<24:13, 10.09s/it]Calculating sensitivities:  11%|#######                                                        | 18/161 [02:37<19:58,  8.38s/it]Calculating sensitivities:  12%|#######4                                                       | 19/161 [02:42<16:59,  7.18s/it]Calculating sensitivities:  12%|#######8                                                       | 20/161 [02:46<14:55,  6.35s/it]Calculating sensitivities:  13%|########2                                                      | 21/161 [02:51<13:27,  5.77s/it]Calculating sensitivities:  14%|########6                                                      | 22/161 [03:08<21:30,  9.29s/it]Calculating sensitivities:  14%|#########                                                      | 23/161 [03:26<27:04, 11.77s/it]Calculating sensitivities:  15%|#########3                                                     | 24/161 [03:43<30:53, 13.53s/it]Calculating sensitivities:  16%|#########7                                                     | 25/161 [03:48<24:28, 10.79s/it]Calculating sensitivities:  16%|##########1                                                    | 26/161 [03:52<19:58,  8.88s/it]Calculating sensitivities:  17%|##########5                                                    | 27/161 [03:57<16:49,  7.54s/it]Calculating sensitivities:  17%|##########9                                                    | 28/161 [04:01<14:36,  6.59s/it]Calculating sensitivities:  18%|###########3                                                   | 29/161 [04:05<13:04,  5.94s/it]Calculating sensitivities:  19%|###########7                                                   | 30/161 [04:10<11:59,  5.49s/it]Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
: ResNet50(
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=10, bias=True)
  )
)
model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)
model.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
model.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.relu: ReLU(inplace=True)
model.maxpool: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
model.layer1: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer1.0: Bottleneck(
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer1.0.conv1: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.0.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.relu: ReLU(inplace=True)
model.layer1.0.downsample: Sequential(
  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer1.0.downsample.0: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.downsample.1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.1.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.1.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.relu: ReLU(inplace=True)
model.layer1.2: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.2.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.2.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.relu: ReLU(inplace=True)
model.layer2: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer2.0: Bottleneck(
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer2.0.conv1: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer2.0.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.relu: ReLU(inplace=True)
model.layer2.0.downsample: Sequential(
  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer2.0.downsample.0: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer2.0.downsample.1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.1.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.1.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.relu: ReLU(inplace=True)
model.layer2.2: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.2.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.2.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.relu: ReLU(inplace=True)
model.layer2.3: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.3.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.3.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.relu: ReLU(inplace=True)
model.layer3: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (4): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (5): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer3.0: Bottleneck(
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer3.0.conv1: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer3.0.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.relu: ReLU(inplace=True)
model.layer3.0.downsample: Sequential(
  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer3.0.downsample.0: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer3.0.downsample.1: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.1.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.1.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.relu: ReLU(inplace=True)
model.layer3.2: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.2.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.2.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.relu: ReLU(inplace=True)
model.layer3.3: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.3.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.3.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.relu: ReLU(inplace=True)
model.layer3.4: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.4.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.4.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.relu: ReLU(inplace=True)
model.layer3.5: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.5.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.5.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.relu: ReLU(inplace=True)
model.layer4: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer4.0: Bottleneck(
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer4.0.conv1: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer4.0.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.relu: ReLU(inplace=True)
model.layer4.0.downsample: Sequential(
  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer4.0.downsample.0: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer4.0.downsample.1: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.1.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.1.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.relu: ReLU(inplace=True)
model.layer4.2: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.2.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.2.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.relu: ReLU(inplace=True)
model.avgpool: AdaptiveAvgPool2d(output_size=(1, 1))
model.fc: Linear(in_features=2048, out_features=10, bias=True)
Calculating sensitivities:   0%|                                                                                                                                                                             | 0/161 [00:00<?, ?it/s]Calculating sensitivities:   1%|#                                                                                                                                                                    | 1/161 [00:04<10:57,  4.11s/it]Calculating sensitivities:   1%|##                                                                                                                                                                   | 2/161 [00:08<11:12,  4.23s/it]Calculating sensitivities:   2%|###                                                                                                                                                                  | 3/161 [00:12<11:27,  4.35s/it]Calculating sensitivities:   2%|####                                                                                                                                                                 | 4/161 [00:17<11:30,  4.40s/it]Calculating sensitivities:   3%|#####1                                                                                                                                                               | 5/161 [00:21<11:28,  4.41s/it]Calculating sensitivities:   4%|######1                                                                                                                                                              | 6/161 [00:26<11:28,  4.44s/it]Calculating sensitivities:   4%|#######1                                                                                                                                                             | 7/161 [00:30<11:28,  4.47s/it]Calculating sensitivities:   5%|########1                                                                                                                                                            | 8/161 [00:35<11:22,  4.46s/it]Calculating sensitivities:   6%|#########2                                                                                                                                                           | 9/161 [00:39<11:18,  4.47s/it]Calculating sensitivities:   6%|##########1                                                                                                                                                         | 10/161 [00:57<21:45,  8.65s/it]Calculating sensitivities:   7%|###########2                                                                                                                                                        | 11/161 [01:15<28:31, 11.41s/it]Calculating sensitivities:   7%|############2                                                                                                                                                       | 12/161 [01:33<33:13, 13.38s/it]Calculating sensitivities:   8%|#############2                                                                                                                                                      | 13/161 [01:51<36:15, 14.70s/it]Calculating sensitivities:   9%|##############2                                                                                                                                                     | 14/161 [02:08<38:15, 15.62s/it]Calculating sensitivities:   9%|###############2                                                                                                                                                    | 15/161 [02:26<39:36, 16.27s/it]Calculating sensitivities:  10%|################2                                                                                                                                                   | 16/161 [02:31<30:43, 12.71s/it]Calculating sensitivities:  11%|#################3                                                                                                                                                  | 17/161 [02:35<24:32, 10.22s/it]Calculating sensitivities:  11%|##################3                                                                                                                                                 | 18/161 [02:39<20:15,  8.50s/it]Calculating sensitivities:  12%|###################3                                                                                                                                                | 19/161 [02:44<17:16,  7.30s/it]Calculating sensitivities:  12%|####################3                                                                                                                                               | 20/161 [02:48<15:11,  6.46s/it]Calculating sensitivities:  13%|#####################3                                                                                                                                              | 21/161 [02:53<13:42,  5.87s/it]Calculating sensitivities:  14%|######################4                                                                                                                                             | 22/161 [03:11<21:59,  9.49s/it]Calculating sensitivities:  14%|#######################4                                                                                                                                            | 23/161 [03:29<27:34, 11.99s/it]Calculating sensitivities:  15%|########################4                                                                                                                                           | 24/161 [03:47<31:21, 13.73s/it]Calculating sensitivities:  16%|#########################4                                                                                                                                          | 25/161 [03:51<24:50, 10.96s/it]Calculating sensitivities:  16%|##########################4                                                                                                                                         | 26/161 [03:56<20:20,  9.04s/it]Calculating sensitivities:  17%|###########################5                                                                                                                                        | 27/161 [04:00<17:09,  7.68s/it]Calculating sensitivities:  17%|############################5                                                                                                                                       | 28/161 [04:05<14:55,  6.73s/it]Calculating sensitivities:  18%|#############################5                                                                                                                                      | 29/161 [04:09<13:21,  6.08s/it]Calculating sensitivities:  19%|##############################5                                                                                                                                     | 30/161 [04:14<12:13,  5.60s/it]Calculating sensitivities:  19%|###############################5                                                                                                                                    | 31/161 [04:31<20:01,  9.24s/it]Calculating sensitivities:  20%|################################5                                                                                                                                   | 32/161 [04:49<25:22, 11.80s/it]Calculating sensitivities:  20%|#################################6                                                                                                                                  | 33/161 [05:07<28:57, 13.57s/it]Calculating sensitivities:  21%|##################################6                                                                                                                                 | 34/161 [05:16<25:44, 12.16s/it]Calculating sensitivities:  22%|###################################6                                                                                                                                | 35/161 [05:25<23:29, 11.19s/it]Calculating sensitivities:  22%|####################################6                                                                                                                               | 36/161 [05:33<21:50, 10.49s/it]Calculating sensitivities:  23%|#####################################6                                                                                                                              | 37/161 [05:42<20:43, 10.03s/it]Calculating sensitivities:  24%|######################################7                                                                                                                             | 38/161 [05:51<19:55,  9.72s/it]Calculating sensitivities:  24%|#######################################7                                                                                                                            | 39/161 [06:01<19:21,  9.52s/it]Calculating sensitivities:  25%|########################################7                                                                                                                           | 40/161 [06:38<35:55, 17.81s/it]Calculating sensitivities:  25%|#########################################7                                                                                                                          | 41/161 [07:15<47:03, 23.53s/it]Calculating sensitivities:  26%|##########################################7                                                                                                                         | 42/161 [07:51<54:39, 27.56s/it]Calculating sensitivities:  27%|###########################################8                                                                                                                        | 43/161 [08:27<58:52, 29.94s/it]Calculating sensitivities:  27%|############################################2                                                                                                                     | 44/161 [09:03<1:01:42, 31.65s/it]Calculating sensitivities:  28%|#############################################2                                                                                                                    | 45/161 [09:38<1:03:27, 32.82s/it]Calculating sensitivities:  29%|##############################################8                                                                                                                     | 46/161 [09:47<49:06, 25.62s/it]Calculating sensitivities:  29%|###############################################8                                                                                                                    | 47/161 [09:56<39:07, 20.59s/it]Calculating sensitivities:  30%|################################################8                                                                                                                   | 48/161 [10:05<32:08, 17.07s/it]Calculating sensitivities:  30%|#################################################9                                                                                                                  | 49/161 [10:14<27:14, 14.60s/it]Calculating sensitivities:  31%|##################################################9                                                                                                                 | 50/161 [10:22<23:49, 12.88s/it]Calculating sensitivities:  32%|###################################################9                                                                                                                | 51/161 [10:31<21:24, 11.68s/it]Calculating sensitivities:  32%|####################################################9                                                                                                               | 52/161 [11:07<34:14, 18.85s/it]Calculating sensitivities:  33%|#####################################################9                                                                                                              | 53/161 [11:43<43:03, 23.92s/it]Calculating sensitivities:  34%|#######################################################                                                                                                             | 54/161 [12:18<48:53, 27.41s/it]Calculating sensitivities:  34%|########################################################                                                                                                            | 55/161 [12:27<38:36, 21.85s/it]Calculating sensitivities:  35%|#########################################################                                                                                                           | 56/161 [12:36<31:25, 17.96s/it]Calculating sensitivities:  35%|##########################################################                                                                                                          | 57/161 [12:45<26:24, 15.24s/it]Calculating sensitivities:  36%|###########################################################                                                                                                         | 58/161 [12:54<22:52, 13.33s/it]Calculating sensitivities:  37%|############################################################                                                                                                        | 59/161 [13:03<20:23, 12.00s/it]Calculating sensitivities:  37%|#############################################################1                                                                                                      | 60/161 [13:12<18:39, 11.08s/it]Calculating sensitivities:  38%|##############################################################1                                                                                                     | 61/161 [13:47<30:43, 18.44s/it]Calculating sensitivities:  39%|###############################################################1                                                                                                    | 62/161 [14:23<39:09, 23.73s/it]Calculating sensitivities:  39%|################################################################1                                                                                                   | 63/161 [14:59<44:51, 27.47s/it]Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
: ResNet50(
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=10, bias=True)
  )
)
model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)
model.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
model.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.relu: ReLU(inplace=True)
model.maxpool: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
model.layer1: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer1.0: Bottleneck(
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer1.0.conv1: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.0.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.relu: ReLU(inplace=True)
model.layer1.0.downsample: Sequential(
  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer1.0.downsample.0: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.downsample.1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.1.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.1.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.relu: ReLU(inplace=True)
model.layer1.2: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.2.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.2.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.relu: ReLU(inplace=True)
model.layer2: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer2.0: Bottleneck(
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer2.0.conv1: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer2.0.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.relu: ReLU(inplace=True)
model.layer2.0.downsample: Sequential(
  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer2.0.downsample.0: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer2.0.downsample.1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.1.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.1.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.relu: ReLU(inplace=True)
model.layer2.2: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.2.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.2.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.relu: ReLU(inplace=True)
model.layer2.3: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.3.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.3.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.relu: ReLU(inplace=True)
model.layer3: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (4): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (5): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer3.0: Bottleneck(
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer3.0.conv1: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer3.0.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.relu: ReLU(inplace=True)
model.layer3.0.downsample: Sequential(
  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer3.0.downsample.0: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer3.0.downsample.1: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.1.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.1.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.relu: ReLU(inplace=True)
model.layer3.2: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.2.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.2.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.relu: ReLU(inplace=True)
model.layer3.3: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.3.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.3.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.relu: ReLU(inplace=True)
model.layer3.4: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.4.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.4.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.relu: ReLU(inplace=True)
model.layer3.5: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.5.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.5.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.relu: ReLU(inplace=True)
model.layer4: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer4.0: Bottleneck(
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer4.0.conv1: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer4.0.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.relu: ReLU(inplace=True)
model.layer4.0.downsample: Sequential(
  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer4.0.downsample.0: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer4.0.downsample.1: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.1.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.1.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.relu: ReLU(inplace=True)
model.layer4.2: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.2.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.2.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.relu: ReLU(inplace=True)
model.avgpool: AdaptiveAvgPool2d(output_size=(1, 1))
model.fc: Linear(in_features=2048, out_features=10, bias=True)
Using device cuda
Files already downloaded and verified
Loading existing best weights from resnet50_cifar10_best_model.pth
Pruning CIFAR-10 with 50.0% using method sensitivity...
: ResNet50(
  (model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=10, bias=True)
  )
)
model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)
model.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
model.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.relu: ReLU(inplace=True)
model.maxpool: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
model.layer1: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer1.0: Bottleneck(
  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer1.0.conv1: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.0.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.0.relu: ReLU(inplace=True)
model.layer1.0.downsample: Sequential(
  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer1.0.downsample.0: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.0.downsample.1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.1.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.1.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.1.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.1.relu: ReLU(inplace=True)
model.layer1.2: Bottleneck(
  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer1.2.conv1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn1: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer1.2.bn2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.conv3: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer1.2.bn3: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer1.2.relu: ReLU(inplace=True)
model.layer2: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer2.0: Bottleneck(
  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer2.0.conv1: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer2.0.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.0.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.0.relu: ReLU(inplace=True)
model.layer2.0.downsample: Sequential(
  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer2.0.downsample.0: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer2.0.downsample.1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.1.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.1.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.1.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.1.relu: ReLU(inplace=True)
model.layer2.2: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.2.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.2.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.2.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.2.relu: ReLU(inplace=True)
model.layer2.3: Bottleneck(
  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer2.3.conv1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn1: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer2.3.bn2: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.conv3: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer2.3.bn3: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer2.3.relu: ReLU(inplace=True)
model.layer3: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (3): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (4): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (5): Bottleneck(
    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer3.0: Bottleneck(
  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer3.0.conv1: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer3.0.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.0.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.0.relu: ReLU(inplace=True)
model.layer3.0.downsample: Sequential(
  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer3.0.downsample.0: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer3.0.downsample.1: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.1.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.1.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.1.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.1.relu: ReLU(inplace=True)
model.layer3.2: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.2.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.2.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.2.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.2.relu: ReLU(inplace=True)
model.layer3.3: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.3.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.3.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.3.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.3.relu: ReLU(inplace=True)
model.layer3.4: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.4.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.4.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.4.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.4.relu: ReLU(inplace=True)
model.layer3.5: Bottleneck(
  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer3.5.conv1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn1: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer3.5.bn2: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.conv3: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer3.5.bn3: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer3.5.relu: ReLU(inplace=True)
model.layer4: Sequential(
  (0): Bottleneck(
    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (downsample): Sequential(
      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (2): Bottleneck(
    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
)
model.layer4.0: Bottleneck(
  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (downsample): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
model.layer4.0.conv1: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
model.layer4.0.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.0.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.0.relu: ReLU(inplace=True)
model.layer4.0.downsample: Sequential(
  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
model.layer4.0.downsample.0: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
model.layer4.0.downsample.1: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.1.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.1.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.1.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.1.relu: ReLU(inplace=True)
model.layer4.2: Bottleneck(
  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
)
model.layer4.2.conv1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn1: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
model.layer4.2.bn2: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.conv3: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
model.layer4.2.bn3: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
model.layer4.2.relu: ReLU(inplace=True)
model.avgpool: AdaptiveAvgPool2d(output_size=(1, 1))
model.fc: Linear(in_features=2048, out_features=10, bias=True)
